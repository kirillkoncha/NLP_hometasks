{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html import unescape\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import html\n",
    "import collections\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция которая загружает рецензии со страницы\n",
    "def getPage(url): \n",
    "    req = session.get(url, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    review_page = soup.find_all('span', {'itemprop': 'reviewBody'})\n",
    "    return review_page\n",
    "\n",
    "#очищает текст от лишних знаков\n",
    "def cleanText(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "#проверяет сами рецензии отрицательные они или положительные\n",
    "def detectReviews(reviews):\n",
    "    cleaned = getCleaned(reviews)\n",
    "    review = []\n",
    "    for c in cleaned:\n",
    "        words = []\n",
    "        good = 0\n",
    "        bad = 0\n",
    "        for word in nltk.word_tokenize(c.lower()):\n",
    "            if word.isalpha() and word not in russian_stopwords:\n",
    "                new = morph.parse(word)[0]\n",
    "                words.append(new.normal_form)   \n",
    "        for i in words:\n",
    "            if i in freqGood:\n",
    "                good += 1\n",
    "            if i in freqBad:\n",
    "                bad += 1\n",
    "        if good >= bad:\n",
    "            print(c[-100:] + ' ПОЛОЖИТЕЛЬНЫЙ ОТЗЫВ')\n",
    "            review.append('положит')\n",
    "        else:\n",
    "            print(c[-100:] + ' ОТРИЦАТЕЛЬНЫЙ ОТЗЫВ')\n",
    "            review.append('отриц')\n",
    "    return review\n",
    "    \n",
    "#функция которая очищает все рецензии от лишних знаков и переводит их в формат списка           \n",
    "def getCleaned(reviews):\n",
    "    reviews_cleaned = []\n",
    "    for review in reviews:\n",
    "        cleaned = cleanText(str(review))\n",
    "        reviews_cleaned.append(cleaned)\n",
    "    return reviews_cleaned\n",
    "\n",
    "#функция составляющая списки слов которые встречаются только в положительных/отрицательных рецензиях.\n",
    "def getWords(words, antiWords):\n",
    "    c = collections.Counter()\n",
    "    new_words = []\n",
    "    freq_words = []\n",
    "    for word in words:\n",
    "        if word not in wordsGood:\n",
    "            new_words.append(word)\n",
    "    for word in words:\n",
    "        c[word] += 1\n",
    "    for key, value in c.items():\n",
    "        if value >= 3 and key not in antiWords:\n",
    "            freq_words.append(key)\n",
    "    return freq_words\n",
    "\n",
    "#токенизирует все и приводит в начальную форму   \n",
    "def tokenizeAndNormalForm(cleaned):\n",
    "    words = []\n",
    "    for review in cleaned:\n",
    "        for i in nltk.word_tokenize(review.lower()):\n",
    "            if i.isalpha() and i not in russian_stopwords:\n",
    "                word = morph.parse(i)[0]\n",
    "                words.append(word.normal_form)\n",
    "    return words       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получим 50 отрицательных и положительных рецензий на ла ла ленд и просто 10 рецензий на новый сезон смешариков.\n",
    "bad_reviews = getPage('https://www.kinopoisk.ru/film/841081/reviews/ord/rating/status/bad/perpage/50/page/1/')\n",
    "good_reviews = getPage('https://www.kinopoisk.ru/film/841081/reviews/ord/rating/status/good/perpage/50/page/2/')\n",
    "reviews = getPage('https://www.kinopoisk.ru/film/1379016/reviews/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedGood = getCleaned(good_reviews)\n",
    "cleanedBad = getCleaned(bad_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsGood = tokenizeAndNormalForm(cleanedGood)\n",
    "wordsBad = tokenizeAndNormalForm(cleanedBad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqGood = getWords(wordsGood, wordsBad)\n",
    "freqBad = getWords(wordsBad, wordsGood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сь сдержать. И осталось долгое послевкусие из светлой грусти и собственного кувшинчика воспоминаний. ПОЛОЖИТЕЛЬНЫЙ ОТЗЫВ\n",
      "ему скромному мнению мультсериал отличный, несмотря на минусы. Рекомендую к просмотру.\n",
      "\n",
      "У меня всё. ОТРИЦАТЕЛЬНЫЙ ОТЗЫВ\n",
      "ики грустные, это жизнь такая.\n",
      "\n",
      "P.S. Анатолий Валентинович, спасибо вам за все, мягких вам облаков. ПОЛОЖИТЕЛЬНЫЙ ОТЗЫВ\n",
      "е убить этот легендарный мультсериал.\n",
      "\n",
      "Эх...\n",
      "\n",
      "Один балл за серию с подкроватным монстром.\n",
      "\n",
      "1 из 10 ОТРИЦАТЕЛЬНЫЙ ОТЗЫВ\n",
      " где раскроют отношение между Карычем и Совуньей.\n",
      "\n",
      "2. Развить мерч.\n",
      "\n",
      "*УДАЧИ С ПРОКТОМ!\n",
      "\n",
      " 10 из 10 ПОЛОЖИТЕЛЬНЫЙ ОТЗЫВ\n",
      "ть Смешарики и всё что с ними связано. \n",
      "\n",
      "И данная серия, как дань этому следу, такая же прекрасная. ПОЛОЖИТЕЛЬНЫЙ ОТЗЫВ\n",
      "ею мультфильма, заложенную в далёком 2003. Всей душой хочется в это верить! \n",
      "\n",
      " Спасибо за внимание. ПОЛОЖИТЕЛЬНЫЙ ОТЗЫВ\n",
      "и» скатятся ещё сильнее. Так что, пока не поздно, ставлю пятёрку первым двенадцати сериям.\n",
      "\n",
      "5 из 10 ОТРИЦАТЕЛЬНЫЙ ОТЗЫВ\n",
      "ей, ничего более.\n",
      "\n",
      "3 из 10. Один за попытку, один за мои тёплые воспоминания и один за мимикрятора. ОТРИЦАТЕЛЬНЫЙ ОТЗЫВ\n",
      "тра. Спасибо вам. Спасибо за полтора часа детства.\n",
      "\n",
      "P.S. Выпустите альбом с саундтреком в Я. Музыке ОТРИЦАТЕЛЬНЫЙ ОТЗЫВ\n"
     ]
    }
   ],
   "source": [
    "#тут проверяем accuracy и выводим результат программы\n",
    "from sklearn.metrics import accuracy_score\n",
    "results = []\n",
    "#взял со страницы https://www.kinopoisk.ru/film/1379016/reviews/\n",
    "gold = ['положит','положит', 'положит', 'отриц', 'положит', 'положит', 'положит', 'отриц', 'отриц', 'положит'] \n",
    "    \n",
    "results = detectReviews(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если говорить про улучшения, то, во-первых, неплохо было бы существенно увеличить объем данных, на которых программа обучается, так как рецензии достаточно большие по объему (в таком случае можно будет еще и оставить слова, которые встречаются больше не двух, а, например, пяти раз). Во-вторых, рецензии скачиваются с сайта КиноПоиск, который при множестве запросов включает капчу. Это можно обойти с помощью selenium'а. Помимо этого, нынешний код иногда нелогичный и содержит \"костыли\". Например, два раза написан код в котором слова приводятся к начальной форме (в функции определяющей тип рецензии и функции отдельно созданной для этого). Можно улучшить получение текста рецензий и парсить не одна страницу, а написать краулер, который бы собирал рецензии со всех страниц. Также, насколько я знаю, у КиноПоиска есть API и нужно посмотреть есть ли там поиск по названию и если есть, то можно автоматизировать программу, что не надо будет вводить ссылки, а просто вбивать названия."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
